{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024cabf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def entropy(data):\n",
    "    \"\"\"\n",
    "    Calculate the entropy of a dataset.\n",
    "    \"\"\"\n",
    "    num_instances = len(data)  # Get the number of instances in the dataset\n",
    "    label_counts = {}  # Initialize an empty dictionary to count the occurrences of each class label\n",
    "    for instance in data:\n",
    "        label = instance[-1]  # Get the class label of the instance\n",
    "        if label not in label_counts:\n",
    "            label_counts[label] = 0  # Initialize the count for this class label if it's not already in the dictionary\n",
    "        label_counts[label] += 1  # Increment the count for this class label\n",
    "    \n",
    "    entropy = 0.0\n",
    "    for label in label_counts:\n",
    "        prob = label_counts[label] / num_instances  # Calculate the probability of each class label\n",
    "        entropy -= prob * math.log2(prob)  # Update the entropy using the formula for entropy\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "def split_data(data, attribute_index):\n",
    "    \"\"\"\n",
    "    Split the dataset based on a given attribute.\n",
    "    \"\"\"\n",
    "    split_data = {}\n",
    "    for instance in data:\n",
    "        attribute_value = instance[attribute_index]  # Get the value of the attribute for the current instance\n",
    "        if attribute_value not in split_data:\n",
    "            split_data[attribute_value] = []  # Initialize an empty list for this attribute value if it's not already in the dictionary\n",
    "        split_data[attribute_value].append(instance)  # Add the instance to the list corresponding to its attribute value\n",
    "    \n",
    "    return split_data\n",
    "\n",
    "def information_gain(data, attribute_index):\n",
    "    \"\"\"\n",
    "    Calculate the information gain for a given attribute.\n",
    "    \"\"\"\n",
    "    entropy_before_split = entropy(data)  # Calculate the entropy of the dataset before splitting\n",
    "    split_data_dict = split_data(data, attribute_index)  # Split the dataset based on the given attribute\n",
    "    entropy_after_split = 0.0\n",
    "    \n",
    "    for attribute_value in split_data_dict:\n",
    "        subset = split_data_dict[attribute_value]  # Get the subset of data for a particular attribute value\n",
    "        prob = len(subset) / len(data)  # Calculate the probability of this attribute value\n",
    "        entropy_after_split += prob * entropy(subset)  # Update the entropy after splitting\n",
    "    \n",
    "    information_gain = entropy_before_split - entropy_after_split  # Calculate the information gain\n",
    "    return information_gain\n",
    "\n",
    "def best_attribute(data):\n",
    "    \"\"\"\n",
    "    Find the attribute that provides the highest information gain.\n",
    "    \"\"\"\n",
    "    num_attributes = len(data[0]) - 1  # Get the number of attributes (excluding the class label)\n",
    "    best_gain = -1  # Initialize the best information gain to a negative value\n",
    "    best_attribute_index = None\n",
    "    \n",
    "    for i in range(num_attributes):\n",
    "        gain = information_gain(data, i)  # Calculate the information gain for each attribute\n",
    "        if gain > best_gain:\n",
    "            best_gain = gain  # Update the best information gain if a better one is found\n",
    "            best_attribute_index = i\n",
    "    \n",
    "    if best_attribute_index is not None:\n",
    "        best_attr = f'Attribute {best_attribute_index + 1}'  # Get the name of the best attribute\n",
    "        return best_attribute_index, best_attr\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def majority_vote(data):\n",
    "    \"\"\"\n",
    "    Determine the majority class label in a dataset.\n",
    "    \"\"\"\n",
    "    label_counts = {}\n",
    "    for instance in data:\n",
    "        label = instance[-1]\n",
    "        if label not in label_counts:\n",
    "            label_counts[label] = 0\n",
    "        label_counts[label] += 1\n",
    "    \n",
    "    majority_label = max(label_counts, key=label_counts.get)  # Get the class label with the highest count\n",
    "    return majority_label\n",
    "\n",
    "def build_tree(data, attributes):\n",
    "    \"\"\"\n",
    "    Recursively build the decision tree.\n",
    "    \"\"\"\n",
    "    if len(set(instance[-1] for instance in data)) == 1:\n",
    "        # If all instances have the same class label, return a leaf node\n",
    "        return data[0][-1]\n",
    "    \n",
    "    best_attribute_index, best_attr = best_attribute(data)  # Find the best attribute to split on\n",
    "    if best_attribute_index is None:\n",
    "        return majority_vote(data)  # If no best attribute is found, return the majority class label\n",
    "    \n",
    "    tree = {best_attr: {}}  # Initialize the tree with the best attribute\n",
    "    \n",
    "    split_data_dict = split_data(data, best_attribute_index)  # Split the data based on the best attribute\n",
    "    for attribute_value in split_data_dict:\n",
    "        subtree = build_tree(split_data_dict[attribute_value], attributes[:])  # Recursively build subtrees\n",
    "        tree[best_attr][attribute_value] = subtree\n",
    "    \n",
    "    return tree\n",
    "\n",
    "def train_decision_tree(data):\n",
    "    \"\"\"\n",
    "    Train the decision tree model using the provided dataset.\n",
    "    \"\"\"\n",
    "    attributes = [f'Attribute {i+1}' for i in range(len(data[0]) - 1)]  # Get attribute names\n",
    "    tree = build_tree(data, attributes)  # Build the decision tree\n",
    "    return tree\n",
    "\n",
    "def predict_instance(instance, tree):\n",
    "    \"\"\"\n",
    "    Predict the class label of a single instance using the trained decision tree.\n",
    "    \"\"\"\n",
    "    if isinstance(tree, dict):\n",
    "        attribute_index = int(list(tree.keys())[0].split()[1]) - 1  # Get the index of the attribute in the instance\n",
    "        attribute_value = instance[attribute_index]  # Get the value of the attribute in the instance\n",
    "        subtree = tree[list(tree.keys())[0]][attribute_value]  # Get the subtree corresponding to the attribute value\n",
    "        return predict_instance(instance, subtree)  # Recursively predict using the subtree\n",
    "    else:\n",
    "        return tree  # If a leaf node is reached, return the class label\n",
    "\n",
    "def predict(instances, tree):\n",
    "    \"\"\"\n",
    "    Predict the class labels of multiple instances using the trained decision tree.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    for instance in instances:\n",
    "        prediction = predict_instance(instance, tree)  # Predict the class label for each instance\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "# Dataset\n",
    "data = [\n",
    "    ['Sunny', 'Hot', 'High', 'Weak', 'No'],\n",
    "    ['Sunny', 'Hot', 'High', 'Strong', 'No'],\n",
    "    ['Overcast', 'Hot', 'High', 'Weak', 'Yes'],\n",
    "    ['Rain', 'Mild', 'High', 'Weak', 'Yes'],\n",
    "    ['Rain', 'Cool', 'Normal', 'Weak', 'Yes'],\n",
    "    ['Rain', 'Cool', 'Normal', 'Strong', 'No'],\n",
    "    ['Overcast', 'Cool', 'Normal', 'Strong', 'Yes'],\n",
    "    ['Sunny', 'Mild', 'High', 'Weak', 'No'],\n",
    "    ['Sunny', 'Cool', 'Normal', 'Weak', 'Yes'],\n",
    "    ['Rain', 'Mild', 'Normal', 'Weak', 'Yes'],\n",
    "    ['Sunny', 'Mild', 'Normal', 'Strong', 'Yes'],\n",
    "    ['Overcast', 'Mild', 'High', 'Strong', 'Yes'],\n",
    "    ['Overcast', 'Hot', 'Normal', 'Weak', 'Yes'],\n",
    "    ['Rain', 'Mild', 'High', 'Strong', 'No']\n",
    "]\n",
    "\n",
    "# Train the decision tree\n",
    "decision_tree = train_decision_tree(data)\n",
    "\n",
    "# Test the decision tree\n",
    "test_data = [\n",
    "    ['Sunny', 'Hot', 'High', 'Weak'],\n",
    "    ['Overcast', 'Cool', 'Normal', 'Strong'],\n",
    "    ['Rain', 'Mild', 'High', 'Weak']\n",
    "]\n",
    "\n",
    "predictions = predict(test_data, decision_tree)\n",
    "print(\"Predictions:\", predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
